{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTot = 20\n",
    "circles_data, circles_labels = make_circles(n_samples = nTot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwUAAAIPCAYAAAAiiXKrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAABYlAAAWJQFJUiTwAABG3ElEQVR4nO3de7xcdXno/88TooRLuIQAWlFITEJSD+gJV9mWRNIi2qLIpXpa47W2XsH7wXoDjx4vVRG8YRVF0RZoRCznJ2h/gUQIChKq2DaShCSIBwVDBBIgwZjn/LHWmM1mZu/Zs/fc9vq8X695rT1rre9lZs1es575XlZkJpIkSZKqa1K3KyBJkiSpuwwKJEmSpIozKJAkSZIqzqBAkiRJqjiDAkmSJKniDAokSZKkijMokCRJkirOoECSJEmqOIMCSZIkqeIMCiRJkqSKMyiQJEmSKs6gQJIkSao4gwJJkiSp4gwKJKmHRMSGiMiIWDjO+Wb5OGQ8821VRJxT1ufibtelGyLikNox6XZdJAkMCiSpKRExLSLeHRHXR8SvI+LRiLgnIm6IiL+PiP26XccqiIjJEfH8iPhMRNwSEQ+Ux+JXEfGvEXHKCOk3DAqQao+t5bH8j4i4JCJeFxH7dOYVja+IeEsZcB3S7bpI6i+Tu10BSep1EfFXwOeAfcpVO4AHgOnAAcAA8M6IeGNm/tMYi7sD2Ao8PMZ8hrq9XP5unPPttC8AfzPo+e8o3q8nAScDJ0fEEuCvMnO41/oQsKX8exdgX4pj+QzgZcCnIuKTwLmZuX18X0JbvQU4GFgGbOhmRST1F1sKJGkYEfF3wDcoAoKVwAuA3TJzGjAFOAn4cbn9G+X+LcvMRZk5NzNvHks+dfKdWz7+73jm2wVPAO4GPgj8d2DXzNwLeApF4AZwOvDhEfL5RGY+qXzsn5lPBJ5KERD8ENgNeC9wdUT4A5qkCc+gQJIaiIj/DlwABPAd4NmZeXVmPgqQmb/LzO8Bx5XbA7ggIp7VpSpXweeBmZn5gcz8SWYmQGbenZlvAi4u93tjROw2mowz85eZ+U2Klp8PlKv/lJEDDEnqewYFktTYh4AnUvwy/fJG3VHK7iWvAH5V7v+/hu4zeABxRDwlIj4fEesiYltE/KTefvXKiog/jojLIuLeiHgkIn4eEedGxJThBu82Gmg8NE1EvCIiboqIzRHxYERcFxF/1ugNiojjI+L8Ms3dZf/+eyPimog4vVG6VmXmzZm5bZhdLi6XuwPzWiwjM/ODwJJy1Zsj4oDR5lMek/eVx2hrOe7h0oj44xHSTY2IV0bE5eU4h/vLY702Iv4xImbXSXNOOWj54HLVdUPGTSwbtO8u5biML0bEynI8xaPl8ft2RJww2tcqqf8ZFEhSHRFxEPD88ulnM/PB4fbPzAeAz5ZP/7xMX88c4CfA64EDGUUf/4j4U4ouTH8J7A88CswA3g9cB+zabF4N8v8yxUX1ERTjJqYCC4FrIuK0OvvvCSwHzgSOBvYEHinr9jzgXyLii2OpUwvuG/T3LmPM60PlcjfgxaNJWL43yyi6OR1K0Yq0O/AS4Gbg2cMkfwXwVeAMYC7we4rv66cDrwX+vfwsDLYFuIfiuAH8tnxee2watO884LvA3wLzKbrBPQo8GTgFWBoR7x7N65XU/wwKJKm+BRQXcgBXNpmmtl8AxzfY55MULQoDmblHZu5J0Qd+WBExHbiU4gLuZuCwzNyb4kL8r4H/BryuyXrW86Iyn9cDe5V5zwR+QPFd8Zk6fet3UPya/mJgv8yspdsXeBPFherfRsQZY6jXaC0ol78DVo8lo8z8KcWxAviTUSY/DziGIkh6FbBn+d48E1hFMWC6kY0UXZaOBnbPzP0ojvs84JvAHsA/RcQeg+r6icx8EnBXuerUQWMmnpSZpw7K/1HgKxSB296ZuXf5OTwQeB9FEPLhiDhmlK9ZUh9z8JQk1Vfr4rGNnTP3jOTnFBdcT6Rx15XtwJ9l5j21FZm5tom83wzsB9wLPC8z7y/T/o7iAnE7cFmT9axnH+BlZZ/6Wr3WR8T/ANZT/Ip8HEWQUNv+MMWv2Y9R1u1zEfEg8HXgDcC/jKFuTSl/nT+7fHpF2XozVj+jeO0zRlGPg4FXl0/fkJkX17Zl5m0R8TyKz0pdmXlpnXUJ/DwiFlNcvP8pRTD5tWbrNSiv1cBr6qy/F/hQRARFC8frgJtGm7+k/mRLgSTVN61c/jYzdwy7Z6nc77fl00b3Lfj64IBgFGq/9P5jLSAYUvblwLoW8q35BfC46VQz826KlgkoWiNG46pyeWxEjLUrTzMuBA4CHmRncDBWteM5bdi9HutUiu/XuymCosfIzE0M31LQUBkc/H/l04FW8mhC7bi1K39JPciWAknqrB+ONkFE7MrOlosbhtn1BoouP624pTaTTx21aUz3rVO3yRR94M+g6BozjaKlZLApZdqNLdZtRBFxNkX3pwRem5kb2lVWE+aXy+uHCSiXD5dBOSblzRQtAk+nGN8x9Ie8P2q1guXMTK+j6Db2xxTHZ+g1Qcv5S+o/BgWSVF9tYOa+ETGpmdaCiJjEzgvnTQ12+00LddmXnReEvxpmv7tbyLtm8zDbtpbLJwxeWXbXqU3JWvMIxWusvV8Hlss9aFNQUN4b4iPl07eXrSbjZaTjWc/+5XK449HwfhERsQD4PxTjRWoeYOdx2A3Yi+I9HbWIeDLFIOg5g1Y/RNEqsoNigPb0VvOX1J/sPiRJ9a0ql7tSzB7TjLns/JX8vxrs8/uxVKrHvI8iINhI0VpwYGbunpkHlINenzJo36iXwViVfew/Xz49JzPPG+ciDiuXY+ma1bSIeALFzfL2BP5/igHru2XmPrVBw8Dbaru3WMynKQKCdcBpwLTM3HPQcTt2LK9BUn+ypUCS6ltG0RUlKKZpXDXczqVTymUyaEDuOKj9gjuJYtDrbQ32e/I4ltmM2iDjN9cbHMvOVoK2KGc1+irF+/LJzDx3nPN/Jjvf0+tHkbTWGjRc95tG255NMS5iE/CicjD3UC2/rxHxRIouQwB/nZk/Gs/8JfUvWwokqY7M/CVwdfn0TRGx13D7l9vfVD79bpl+vOqyjZ0tD88ZZtfRTps5VrV7Mfx7g+1D59IfNxFxMsX0nLsAF2bmO9pQzHvL5cPAt0eR7tZy+ZxyJp96FjRYX3tPVzcICGD497XWbatRudPZeT+Ljh83Sb3LoECSGns/xXz3fwR8veza8TjlYNuvUfyq/Lsy3XirXZS+NiL2rlOH02h9kHGralN+HjZ0Qzne4D3tKLS8w/K/UIxx+BrFlKfjmX9ExPvYef+I8zNzNGNBrqC4OH8K8LI6+e9L43tK1N7T2RExpU7aE4HnDlN27SZ7+zTYvpmiJQvqH7cnUwxwllQxBgWS1EBmrgTeWj59EXBjRJxUCw4iYnJ5kbaCnV2H3pKZtz4us7H7DEU3ogOBqyPiGYPq8FKKbjT3t6Hc4fxbufxURCyo/SoeEUcBS2k8LWvLImKA4iZxu1LczO3Vw8yaNNq8nxIRf0VxPD9Yrv4eowzyMvNOipuDAVwYES8f9Jk5DLiGYkamelZQtEzsRxGIPrlMt1tEvBr4Fo+9a/NQ/1ku/0e9oCIzNwO1LkNfiYhnlflPiohFFLMitWX8h6TeZlAgScPIzM8BL6f4BfdIii5FWyPiPorZYL5HcefZB4GXZ+bnG+U1xnr8BvgfFDdTezbwHxFxP8Vdg/+ZYpzBheXu29pRhzreSzHI+KkUYzAejogtlHdcBv6qDWX+L2D38u8/Be6OiF83eLxkmHzeMWi/30TENuCXFF2Snk1xYf5B4C8yc3sL9XwrxY2/dqdozdhcHq/bgGdQ3Dn6ccp7ULy7fHpG+frup/h8XQSsBYYbO3HRoLQPRMRdEbEhIgaP+XgrxSxRhwH/Xh6zLRQDm/ejzo3NJE18BgWSNILMvIRirvj3UPySex/FvPGbgBspZuF5erlfO+vxPYrAZElZh10p7jb8AWARxVSV0KEWg8xcRxEQfYPiTsu7lGV/EzgqM7/fhmIHf29Np2g5afTY7XGpd9pj0H57UVx0/xdF3V8H/FFmfqDFgIDM3AIspGhlWF2u3kpx1+mjGeZ+FZl5AcUN0GqtBpMp7oD8AYrZnhpOH5uZ1wIvpvjF/xGKLkwHA08atM9NFIHPlRStT0+gOH5fBJ4F/HQ0r1XSxBDj1OoqSeqyiLieYiDyqzLz4i5XR5LURwwKJGkCiIhnU7Ra7AAOycy7ulwlSVIf8T4FktQnIuJvKbrMXAZsyMzfl7P8nArUbtp1uQGBJGm0bCmQpD4RER9i5zSfv6cY/LwPO/vZ/wT4s8zc2PHKSZL6mi0FktQ/LqUYPLuA4iZX09g5QHYJxU28Hule9SRJ/cqWAkmSJKninJJUkiRJqjiDAkmSJKniDAokSZKkijMokCRJkirOoECSJEmqOKck7YCIWA/sBWzoclUkSZI0sR0CPJiZM0aTyKCgM/babbfdps2bN29atysiSZKkiWvVqlU88sjob1ljUNAZG+bNmzdt5cqV3a6HJEmSJrAjjjiCW2+9dcNo0zmmQJIkSaq4nggKIuL0iPhMRFwfEQ9GREbEN1rM66CI+EpE3B0R2yJiQ0R8OiL2HSbNH0fE5RFxb0RsjYjbI+LciNit9VclSZIk9Yde6T70XuCZwBbgl8DcVjKJiKcDNwIHAN8Bfg4cDZwFnBQRA5l535A0xwDXAk8AlgB3AScA7wcWRcSizNzWSn0kSZKkftATLQXAW4E5FDP0vH4M+XyeIiA4MzNPycyzM/ME4DzgUODDg3eOiF2ArwK7A6dn5l9l5v8EjgG+BQyUdZMkSZImrJ4ICjLzusxck5nZah5lK8GJFNN+fm7I5g8ADwGLI2KPQesXAPOAH2Tmvw6qzw7gXeXT10VEtFovSZIkqdf1RFAwTp5bLr9fXtT/QWZuBlZQtAgcO2jTCeXymqGZZeY6YDVwMDBz3GsrSZIk9YheGVMwHg4tl6sbbF9D0ZIwB1g6ijRzyscdI1UgIhrNOdrSGAlJkiSpEyZSS8He5fKBBttr6/cZYxpJkiRpQplILQVdl5lH1FtftiDM73B1JEmSpKZMpJaC2q/6ezfYXlt//xjTSJIkSRPKRGopuL1czmmwfXa5HDx+oJU0ktRWq+/ZzIq1G9mydTt7TpnMwKzpzDlwarerpQ7yMyCp0yZSUHBduTwxIiYNnoEoIqZS3HPgYeBHg9JcC7wHOAn4yODMImImRbBwJ7CujfWWJABWrN3I+UvXcPP6TY/bdvSMaZy1aDYDs6Z3oWbqFD8Dkrql77oPRcQTImJueV+CP8jMO4DvA4cAbxyS7FxgD+CSzHxo0PrlwCrg+Ih44aAyJgEfK59eOJb7J0hSMy778S9YfNFNdS8GAW5ev4nFF93E5T++q8M1U6f4GZDUTT3RUhARpwCnlE+fVC6fHREXl39vzMx3lH8/heJC/k6KAGCwNwA3AhdExKJyv2Mo7mGwmqJV4A8y8/cR8SqKFoMlEbEE+AWwCDiS4t4G5435BUrSMFas3ci7r/gZO0b4+WFHwtlX3MZT9t3NX4snGD8DkrqtV1oKngW8onw8r1w3c9C605vJpGwtOBK4mCIYeDvwdOB84NjMvK9OmpuAo4DvUNzH4K0UA4w/CPxZZm5r8TVJUlPOX7pmxIvBmh0JFyxd094KqeP8DEjqtp5oKcjMc4Bzmtx3AxDDbL8LeNUoy/8v4IzRpJGk8bD6ns0Nu4s0ctP6Tay+Z7MDTycIPwOSekGvtBRIUiWtWLuxo+nUe/wMSOoFBgWS1EVbtm7vaDr1Hj8DknqBQYEkddGeU1rrxdlqOvUePwOSeoFBgSR1UaszyDjzzMThZ0BSLzAokKQumnPgVI6eMW1UaY6ZMc0BphOInwFJvcCgQJK67KxFs5nUcE61x5oUcOai2e2tkDrOz4CkbjMokKQuG5g1nY+cetiIF4WTAj566uF2G5mA/AxI6jZHKUlSD3jJUU/joH1354Kla7ipzpz1x8yYxpmLZnsxOIH5GZDUTQYFktQjBmZNZ2DWdFbfs5kVazeyZet29pwymYFZ0+0/XhF+BiR1i0GBJPWYOQdO9QKw4vwMSOo0xxRIkiRJFWdQIEmSJFWcQYEkSZJUcQYFkiRJUsUZFEiSJEkVZ1AgSZIkVZxBgSRJklRxBgWSJElSxRkUSJIkSRVnUCBJkiRVnEGBJEmSVHEGBZIkSVLFGRRIkiRJFWdQIEmSJFWcQYEkSZJUcQYFkiRJUsUZFEiSJEkVZ1AgSZIkVZxBgSRJklRxBgWSJElSxRkUSJIkSRVnUCBJkiRVnEGBJEmSVHEGBZIkSVLFTe52BSRJ4+DeVbBuOWzbDLtOhZkL4IB53a6VwGMjqS8YFEhSP1u3DJZ/HO5c8fhtBw/AgnfBzIWdrpXAYyOpr9h9SJL61a1fh0teXP+iE4r1l7wYbr2ks/WSx0ZS3+mpoCAiDoqIr0TE3RGxLSI2RMSnI2LfJtMvjIhs4vHUIemG2/dH7Xm1kjQG65bBVWdB7hh+v9wBV51Z7K/O8NhI6kM9030oIp4O3AgcAHwH+DlwNHAWcFJEDGTmfSNkswE4t8G2w4BTgf/IzLvqbL8TuLjO+l+OWHlJ6rTlHx/5orMmd8Dyf7CrSqd4bCT1oZ4JCoDPUwQEZ2bmZ2orI+JTwFuBDwOvGy6DzNwAnFNvW0T8c/nnlxok35CZddNKUk+5d1XjbimN3HlDkc4Bru3lsZHUp3qi+1DZSnAixS/9nxuy+QPAQ8DiiNijxfynAy8GHgG+3npNJakHrFve2XRqnsdGUp/qlZaC55bL72c+ts01MzdHxAqKoOFYYGkL+b8C2BX4embe32CffSLi1cCTgAeAlZnpeAJJvWfb5s6mU/M8NpL6VK8EBYeWy9UNtq+hCArm0FpQ8Npy+cVh9nkmcNHgFRHxU2BxZv6smUIiYmWDTXObSS9JTdl1amfTqXkeG0l9qie6DwF7l8sHGmyvrd9ntBlHxAKKoOM/MvPGBrt9ChgA9gemAkcBSygChWsj4imjLVeS2mbmgs6mU/M8NpL6VK8EBe30t+XyHxvtkJlvz8wbM3NjZm7JzFsy8wzgW8B04B3NFJSZR9R7UMykJEnj44B5xc2vRuPg5ziQtRM8NpL6VK8EBbWWgL0bbK+tv380mUbENOA0igHGrdwh5sJyeXwLaSWpfRa8C6LJU3hMggXvbG99tJPHRlIf6pWg4PZyOafB9tnlstGYg0ZqA4wvH2aA8XB+Uy5bmvVIktpm5kI4+fyRLz5jEpx8gfPgd5LHRlIf6pWg4LpyeWLEY8+iETGVor//w8BoZwOqDTBu2HVoBMeWy3Utppek9pn/clj87aL7ST0HP6fYPn9xZ+slj42kvtMTsw9l5h0R8X2KGYbeCHxm0OZzKX6p/2JmPlRbGRFzy7R1++tHxJ8A8xh+gDERcTiwKjN/V2f9h8un3xj1i5KkTpi5sHjcu6qY637b5mImm5kL7KfebR4bSX2kJ4KC0huAG4ELImIRsAo4huIeBquB9wzZf1W5jAb5jTjAuPQ24OSIuB64C9hGMYXoScAuFHdA/ufGySWpBxwwzwvNXuWxkdQHeiYoKFsLjgQ+SHFB/gLgV8D5wLmZ+dtm84qIfYHTaW6A8ZXAXsDhwAnAFOA+4GrgS5n5r6N7JZIkSVJ/6ZmgACAz7wJe1eS+jVoIKAOI3ZrM50qKwECSJEmqpF4ZaCxJkiSpSwwKJEmSpIozKJAkSZIqzqBAkiRJqjiDAkmSJKniDAokSZKkijMokCRJkirOoECSJEmqOIMCSZIkqeIMCiRJkqSKMyiQJEmSKs6gQJIkSao4gwJJkiSp4gwKJEmSpIozKJAkSZIqzqBAkiRJqjiDAkmSJKniDAokSZKkipvc7QpI6o7V92xmxdqNbNm6nT2nTGZg1nTmHDi129WSpJ7n+VMTkUGBVDEr1m7k/KVruHn9psdtO3rGNM5aNJuBWdO7UDNJ6m2ePzWR2X1IqpDLfvwLFl90U90vNICb129i8UU3cfmP7+pwzSSpt3n+1ERnUCBVxIq1G3n3FT9jRw6/346Es6+4jRVrN3amYpLU4zx/qgoMCqSKOH/pmhG/0Gp2JFywdE17KyRJfcLzp6rAoECqgNX3bG7Y5N3ITes3sfqezW2qkST1B8+fqgqDAqkCWm3KtglcUtV5/lRVGBRIFbBl6/aOppOkicLzp6rCoECqgD2ntDb7cKvpJGmi8PypqjAokCqg1XmznW9bUtV5/lRVGBRIFTDnwKkcPWPaqNIcM2Oad+iUVHmeP1UVBgVSRZy1aDaTorl9JwWcuWh2eyskSX3C86eqwKBAqoiBWdP5yKmHjfjFNingo6cebtO3JJU8f6oKHAUjVchLjnoaB+27OxcsXcNNdebdPmbGNM5cNNsvNEkawvOnJjqDAqliBmZNZ2DWdFbfs5kVazeyZet29pwymYFZ0+0DK0nD8PypicygQKqoOQdO9UtMklrg+VMTkWMKJEmSpIozKJAkSZIqzqBAkiRJqrieCgoi4qCI+EpE3B0R2yJiQ0R8OiL2HUUeyyIih3lMaZDujyPi8oi4NyK2RsTtEXFuROw2fq9QkiRJ6j09M9A4Ip4O3AgcAHwH+DlwNHAWcFJEDGTmfaPI8twG67fXKfsY4FrgCcAS4C7gBOD9wKKIWJSZ20ZRtiRJktQ3eiYoAD5PERCcmZmfqa2MiE8BbwU+DLyu2cwy85xm9ouIXYCvArsDL8rMfy3XTwIuB04ry/9os2VLkiRJ/aQnug+VrQQnAhuAzw3Z/AHgIWBxROzRhuIXAPOAH9QCAoDM3AG8q3z6uoho8gbnkiRJUn/piaAAeG65/H55Mf4HmbkZWEHxS/6xzWYYES+JiLMj4m0R8fyI2LXBrieUy2uGbsjMdcBq4GBgZrNlS5IkSf2kV7oPHVouVzfYvoaiJWEOsLTJPC8d8vzeiHhjZi5poew55eOO4QqMiJUNNs0dLp1UWfeugnXLYdtm2HUqzFwAB8zrdq0k9SrPGVLb9EpQsHe5fKDB9tr6fZrI6zvAJ4B/B+6j+JX/FcDbgcsi4s8zc3CrwHiWLakZ65bB8o/DnSsev+3gAVjwLpi5sNO1ktSrPGdIbdcrQcG4yczzhqy6Hfj7iLgb+AzwEep0FRqnso+ot75sQZjfjjKlvnPr1+Gqs+CxPQV3unMFXPJiOPkCmL+4s3WT1Hs8Z0gd0StjCmq/xu/dYHtt/f1jKOPLFNORPisipna4bElQ/No33Jd7Te6Aq84s9pdUXZ4zpI7plaDg9nI5p8H22eWyUb//EWXmVmBz+XTwLEZtL1tSafnHR/5yr8kdsPwf2lsfSb3Nc4bUMb0SFFxXLk8s7w/wB+Wv+gPAw8CPWi0gIg4F9qUIDDYO2nRtuTypTpqZFMHCncC6VsuWRDFAsF5/4OHceUORTlL1eM6QOqongoLMvAP4PnAI8MYhm8+l+GX/ksx8qLYyIuZGxGNm9YmIGRExbWj+EbE/xQ3KAC7NzMF3NV4OrAKOj4gXDkozCfhY+fTCzMxWXpuk0rrlnU0nqb95zpA6qpcGGr8BuBG4ICIWUVyoH0NxD4PVwHuG7F/7KWDwTcUWABdGxA0Uv+xvAp4GvIBibMAt7LwhGQCZ+fuIeBVFi8GSiFgC/AJYBBxJcY+EoYOXJY3Wts0j7zOe6ST1N88ZUkf1TFCQmXdExJHABym68rwA+BVwPnBuZv62iWxWUtyf4AjgvwN7UXQX+hlwOfDFzHy0Ttk3RcRRFK0SJwJTKboMfRD4aGZuG+PLk7Tr1JH3Gc90kvqb5wypo3omKADIzLuAVzW5b9RZ9zPglS2W/V/AGa2kldSEmQs6m05Sf/OcIXVUT4wpkFQBB8wrbjI0Ggc/x7uVSlXlOUPqKIMCSZ2z4F0QTZ52YhIseGd76yOpt3nOkDrGoEBS58xcCCefP/KXfEwq7k46c2EnaiWpV3nOkDrGoEBSZ81/OSz+dtHMX8/Bzym2z1/c2XpJ6k2eM6SO6KmBxpIqYubC4nHvqmJO8W2bixlDZi6wP7Ckx/OcIbWdQYGk7jlgnl/okprnOUNqG7sPSZIkSRVnUCBJkiRVnEGBJEmSVHEGBZIkSVLFGRRIkiRJFWdQIEmSJFWcQYEkSZJUcQYFkiRJUsUZFEiSJEkVZ1AgSZIkVZxBgSRJklRxBgWSJElSxRkUSJIkSRVnUCBJkiRVnEGBJEmSVHEGBZIkSVLFGRRIkiRJFWdQIEmSJFWcQYEkSZJUcQYFkiRJUsUZFEiSJEkVZ1AgSZIkVZxBgSRJklRxBgWSJElSxRkUSJIkSRVnUCBJkiRVnEGBJEmSVHEGBZIkSVLFGRRIkiRJFWdQIEmSJFWcQYEkSZJUcT0VFETEQRHxlYi4OyK2RcSGiPh0ROzbZPo9IuKvI+KfIuLnEfFQRGyOiFsi4u0R8cQG6XKYx4/G91VKkiRJvWVytytQExFPB24EDgC+A/wcOBo4CzgpIgYy874RsvkT4BvAJuA64EpgX+CFwCeAUyNiUWZurZP2TuDiOut/OeoXI0mSJPWRngkKgM9TBARnZuZnaisj4lPAW4EPA68bIY9fAy8D/iUzHx2UxzuAZcBxwBuBT9ZJuyEzzxlD/SVJkqS+1BPdh8pWghOBDcDnhmz+APAQsDgi9hgun8z8SWZ+c3BAUK7fzM5AYOF41FmSJEmaKHqlpeC55fL7mblj8IbM3BwRKyiChmOBpS2W8btyub3B9n0i4tXAk4AHgJWZ6XgCSZIkTXi9EhQcWi5XN9i+hiIomEPrQcGry+U1DbY/E7ho8IqI+CmwODN/1kwBEbGywaa5TdVQkiRJ6oKe6D4E7F0uH2iwvbZ+n1Yyj4g3AScBPwG+UmeXTwEDwP7AVOAoYAlFoHBtRDyllXIlSZKkftArLQVtExGnAp+mGIR8Wmb+bug+mfn2IatuAc6IiCXAacA7KAY7Dyszj2hQh5XA/NHVXJIkSeqMXmkpqLUE7N1ge239/aPJNCJOAS4F7gUWZua6UdbrwnJ5/CjTSZIkSX2jV4KC28vlnAbbZ5fLRmMOHicizgD+BbgHWJCZt4+QpJ7flMthZz2SJEmS+lmvBAXXlcsTI+IxdYqIqRT9/R8GmpoNKCL+Gvhn4G6KgGBNi/U6tlyOtoVBkiRJ6hs9ERRk5h3A94FDKG4uNti5FL/UX5KZD9VWRsTciHjcrD4R8Qrg68AvgONH6jIUEYdHxBPqrae4YRoUd0mWJEmSJqReGmj8BuBG4IKIWASsAo6huIfBauA9Q/ZfVS6jtiIinksxu9AkitaHV0XEkGTcn5mfHvT8bcDJEXE9cBewjWIK0ZOAXYAvUbQ6SJIkSRNSzwQFmXlHRBwJfJDigvwFwK+A84FzM/O3TWRzMDtbP17dYJ87KWYjqrkS2As4HDgBmALcB1wNfCkz/3VUL0SSJEnqMz0TFABk5l3Aq5rc93FNAJl5MXDxKMu8kiIwkCRJkiqpJ8YUSJIkSeoegwJJkiSp4gwKJEmSpIozKJAkSZIqzqBAkiRJqjiDAkmSJKniDAokSZKkijMokCRJkirOoECSJEmqOIMCSZIkqeIMCiRJkqSKMyiQJEmSKs6gQJIkSao4gwJJkiSp4gwKJEmSpIozKJAkSZIqzqBAkiRJqjiDAkmSJKniDAokSZKkijMokCRJkirOoECSJEmqOIMCSZIkqeIMCiRJkqSKMyiQJEmSKs6gQJIkSao4gwJJkiSp4gwKJEmSpIozKJAkSZIqzqBAkiRJqjiDAkmSJKniDAokSZKkijMokCRJkirOoECSJEmqOIMCSZIkqeIMCiRJkqSKMyiQJEmSKm5ytysgTVSr79nMirUb2bJ1O3tOmczArOnMOXBqt6v1WPeugnXLYdtm2HUqzFwAB8zrdq0kqTf1yTmzL75/1HN6JiiIiIOADwInAfsBvwKuBM7NzN+OIp9pwPuBU4AnA/cB1wDvz8xftrNsCWDF2o2cv3QNN6/f9LhtR8+YxlmLZjMwa3oXajbIumWw/ONw54rHbzt4ABa8C2Yu7HStJKk39ck5sy++f9SzIjO7XQci4unAjcABwHeAnwNHA88FbgcGMvO+JvLZr8xnDnAt8GNgLvAi4F7g2Zm5rh1lj1CvlfPnz5+/cuXKsWSjPnDZj3/Bu6/4GTuG+beaFPDRUw/nL496aucqNtitX4erzoLc0XifmAQnXwDzF3euXpLUi/rknNkX3z/qiCOOOIJbb7311sw8YjTpemVMwecpLsrPzMxTMvPszDwBOA84FPhwk/n8b4qA4FOZuajM5xTgrDL/z7exbFXcirUbRzwhA+xIOPuK21ixdmNnKjbYumUjf7lBsf2qM4v9Jamq+uSc2RffP+p5XQ8Kyl/qTwQ2AJ8bsvkDwEPA4ojYY4R89gQWl/ufM2TzZ4E7gedFxMzxLlsCOH/pmhFPyDU7Ei5Yuqa9Fapn+cdH/nKryR2w/B/aWx9J6mV9cs7si+8f9byuBwUU3XQAvp/52P+8zNwMrAB2B44dIZ9jgd2AFWW6wfnsAL43pLzxLFsVt/qezXX7cA7npvWbWH3P5pF3HC/3rqrfH3Y4d95QpJOkqumTc2ZffP+oL/RCUHBouVzdYHstnJ3ThnzGq2ygGDtQ70ExrkETWKtNsR1twl23vLPpJKmf9ck5sy++f9QXeiEo2LtcPtBge239Pm3IZ7zKVsVt2bq9o+lasq3FX4VaTSdJ/axPzpl98f2jvtAzU5JOBI1GeZetBfM7XB110J5TWvtXajVdS3ZtcY7qVtNJUj/rk3NmX3z/qC/0QktB7df4vRtsr62/vw35jFfZqrhW533u6HzRMxd0Np0k9bM+OWf2xfeP+kIvBAW3l8tG/fZnl8tG/f7Hks94la2Km3PgVI6eMW1UaY6ZMa2zd5g8YF5xk53ROPg5PXm3Tklquz45Z/bF94/6Qi8EBdeVyxMj4jH1iYipwADwMPCjEfL5EfAIMFCmG5zPJIqpRweXN55lS5y1aDaTorl9JwWcuWj2yDuOtwXvKm6y04yYBAve2d76SFIv65NzZl98/6jndT0oyMw7gO8DhwBvHLL5XGAP4JLMfKi2MiLmRsRjZvTJzC3AJeX+5wzJ501l/t8bfEfjVsqWGhmYNZ2PnHrYiCfm2h0lu9J0O3MhnHz+yF9ytbtzzlzYiVpJUm/qk3NmX3z/qOdFZpN3u2hnJYqbiN1IcWfh7wCrgGMo7iOwGjguM+8btH8CZGYMyWe/Mp85wLXAzcA84EXAvWU+d4yl7BZf38r58+fPX7ly5ViyUZ9YsXYjFyxdw0115o0+ZsY0zlw0u/sn5HXLipvs3HnD47cd/Jzi1y4DAkkq9Mk5sy++f9R2RxxxBLfeeuutjSbAaaQnggKAiHgq8EHgJGA/4FfAt4FzM/O3Q/atGxSU26ZR3I34FODJwH3A1cD7M/OXYy27xddmUFBBq+/ZzIq1G9mydTt7TpnMwKzpvdeH895VxZza2zYXM2bMXOAYAklqpE/OmX3x/aO26fugYCIzKJAkSVIntBoUdH1MgSRJkqTuMiiQJEmSKs6gQJIkSao4gwJJkiSp4gwKJEmSpIozKJAkSZIqzqBAkiRJqjiDAkmSJKniDAokSZKkijMokCRJkirOoECSJEmqOIMCSZIkqeIMCiRJkqSKMyiQJEmSKs6gQJIkSao4gwJJkiSp4gwKJEmSpIozKJAkSZIqzqBAkiRJqjiDAkmSJKniDAokSZKkijMokCRJkirOoECSJEmqOIMCSZIkqeIMCiRJkqSKMyiQJEmSKs6gQJIkSao4gwJJkiSp4gwKJEmSpIozKJAkSZIqzqBAkiRJqjiDAkmSJKniDAokSZKkijMokCRJkirOoECSJEmqOIMCSZIkqeIMCiRJkqSK65mgICKOi4jvRsSmiHgkIm6LiLdExC6jyOMpEfHmiLg6IjZExLaIuC8i/i0iTm2QZmFE5DCPj47fq5QkSZJ6z+RuVwAgIl4EfAvYClwGbAJOBs4DBoAzmszqzcD/BNYD1wG/Bg4GTgX+NCLOy8y3NUi7HFhWZ/0NTZYtSZIk9aWuBwURsRfwJeD3wMLMvKVc/z7gWuD0iHhpZl7aRHY3l3ksH1LGPOBHwFsj4puZubJO2mWZec4YXookSZLUl3qh+9DpwP7ApbWAACAztwLvLZ++vpmMMvOKoQFBuX4VRQsEwMIx1VaSJEmaYLreUgCcUC6vqbPtB8DDwHERsWtmbhtDOb8rl9sbbJ8VEW8C9qLodnR9Zq4ZQ3mSJElSX+iFoODQcrl66IbM3B4R64FnADOBVa0UUHZROg1I4PsNdvvr8jE43beA12bmb5ssp163JIC5TVZVkiRJ6rhe6D60d7l8oMH22vp9Wsk8IgL4MnAg8IWyK9FgvwHOBg4DplJ0ZXo+8O8UgcRVEdEL75MkSZLUFuPSUhARGyhm+WnWNzPzZeNRdhM+STF70fXA42Yeysz/BP5z0KotwDURcSPwE4rZj04GvjNSQZl5RL31ZQvC/NFWXJIkSeqE8eo+dAfFdKLNunvQ37WWgL3r7Tho/f2jrBMR8XHgrRRjE/58NGMSMvPBiPgn4D3A8TQRFEiSJEn9aFyCgsxcNIbktwNHAnOAx/TJj4jJwAyKwcHrRpNpRJwHvIXifgV/kZkPt1C335TLPVpIK0mSJPWFXugrf225PKnOtuOB3YEbm/2VPwqfowgI/o2ihaCVgADg2HI5qoBEkiRJ6ie9EBQsATYCL42II2srI2IK8KHy6RcGJ4iI3SNibkQ8bcj6AP4ReANwNfDCzHxkuMIHlzlk/cuAlwCPApeP6hVJkiRJfaTrU5KWffdfSxEcLIuIS4FNwAsppitdws4bj9UcTdEtaDmPvRnZ+4G/AR6hGCR8dhEnPMZPMvPKQc+XRMR24Bbgl8AU4KiyjO3A32XmhrG8RkmSJKmXdT0oAMjMKyNiAcWg3tMoLszXUswWdEFmZpNZzSiXuwHvbrDP14ArBz3/AvCnFLMMTQcC+L/AxcCnM/OnTb8QSZIkqQ/1RFAAkJkrgBc0ue8yiov3oetfCbxylOV+DPjYaNJIkiRJE0kvjCmQJEmS1EUGBZIkSVLFGRRIkiRJFWdQIEmSJFWcQYEkSZJUcQYFkiRJUsUZFEiSJEkVZ1AgSZIkVZxBgSRJklRxBgWSJElSxRkUSJIkSRVnUCBJkiRVnEGBJEmSVHEGBZIkSVLFGRRIkiRJFWdQIEmSJFWcQYEkSZJUcQYFkiRJUsUZFEiSJEkVZ1AgSZIkVZxBgSRJklRxBgWSJElSxRkUSJIkSRVnUCBJkiRVnEGBJEmSVHEGBZIkSVLFGRRIkiRJFWdQIEmSJFWcQYEkSZJUcQYFkiRJUsVN7nYFJFXYvatg3XLYthl2nQozF8AB87pdK0m9ynOG1DYGBZI6b90yWP5xuHPF47cdPAAL3gUzF3a6VpJ6lecMqe3sPiSps279Olzy4vpf7lCsv+TFcOslna2XpN7kOUPqCIMCSZ2zbhlcdRbkjuH3yx1w1ZnF/pKqy3OG1DEGBZI6Z/nHR/5yr8kdsPwf2lsfSb3Nc4bUMQYFkjrj3lWNm/8bufOGIp2k6vGcIXWUQYGkzli3vLPpJPU3zxlSR/VMUBARx0XEdyNiU0Q8EhG3RcRbImKXUeaTwzx+NEy6v4iIZRHxQERsiYibIuIVY39lkoBiCsFOppPU3zxnSB3VE1OSRsSLgG8BW4HLgE3AycB5wABwxiizvBO4uM76XzYo/03AZ4D7gG8AjwKnAxdHxGGZ+Y5Rli9pqF2ndjadpP7mOUPqqK4HBRGxF/Al4PfAwsy8pVz/PuBa4PSIeGlmXjqKbDdk5jlNln8I8AmKQOTIzNxQrv8g8GPg7RHxrcz84SjKlzTUzAWdTSepv3nOkDqqF7oPnQ7sD1xaCwgAMnMr8N7y6evbWP6rgV2Bz9YCgrL83wL/u3z6ujaWL1XDAfOKmwyNxsHP8W6lUlV5zpA6qheCghPK5TV1tv0AeBg4LiJ2HUWe+0TEqyPi7yPijRFxbIvlXz1kH0ljseBdEE2edmISLHhne+sjqbd5zpA6pheCgkPL5eqhGzJzO7CeopvTzFHk+UzgIuDDwGeBH0bETyLisFGW/yvgIeCgiNh9pEIjYmW9BzB3FHWXJq6ZC+Hk80f+ko9JcPIFxf6SqstzhtQxvRAU7F0uH2iwvbZ+nybz+xTF4OT9ganAUcASikDh2oh4Sovl791gu6TRmP9yWPztopm/noOfU2yfv7iz9ZLUmzxnSB0xLgONI2IDcPAoknwzM182HmUPlZlvH7LqFuCMiFgCnAa8A3hrm8o+ot76srVgfjvKlPrSzIXF495VxZzi2zYXM4bMXGB/YEmP5zlDarvxmn3oDorpRJt196C/R/olvrb+/lHWaagLKYKC44esfwCYXpZz3zDlN2pJkNSqA+b5hS6peZ4zpLYZl6AgMxeNIfntwJHAHGDl4A0RMRmYAWwH1o2hDIDflMs96pQ/vSz/MdOORsSTy/1/mZkPj7F8SZIkqSf1wpiCa8vlSXW2HQ/sDtyYmdvGWE5tBqKhwcVw5T9/yD6SJEnShNMLQcESYCPw0og4srYyIqYAHyqffmFwgojYPSLmRsTThqw/PCKeMLSAiDicYiYiKO5YPNhXgW3Am8obmdXS7Av8ffn0wtG+KEmSJKlfdP2Oxpn5YES8liI4WBYRl1LcXfiFFNOFLgEuG5LsaOA6YDmwcND6twEnR8T1wF0UF/tzKVoBdqG4c/I/Dyl/fUS8E7gAuCUiLgMepbip2kHAJ72bsSRJkiayrgcFAJl5ZUQsAN5DMRh4CrCW4iL/gszMJrO6EtgLOJzihmNTKAYPXw18KTP/tUH5nylnUHoH8HKKFpT/At6bmV9r8WVJkiRJfaEnggKAzFwBvKDJfZcBUWf9lRSBQSvlXwVc1UpaSZIkqZ/1wpgCSZIkSV1kUCBJkiRVXM90H5LUWavv2cyKtRvZsnU7e06ZzMCs6cw5cGq3qyVJPc/zpyYigwKpYlas3cj5S9dw8/pNj9t29IxpnLVoNgOzpnehZpLU2zx/aiKz+5BUIZf9+Bcsvuimul9oADev38Tii27i8h/f1eGaSVJv8/ypic6gQKqIFWs38u4rfsaOESb43ZFw9hW3sWLtxs5UTJJ6nOdPVYFBgVQR5y9dM+IXWs2OhAuWrmlvhSSpT3j+VBUYFEgVsPqezQ2bvBu5af0mVt+zuU01kqT+4PlTVWFQIFVAq03ZNoFLqjrPn6oKgwKpArZs3d7RdJI0UXj+VFUYFEgVsOeU1mYfbjWdJE0Unj9VFQYFUgW0Om+2821LqjrPn6oKgwKpAuYcOJWjZ0wbVZpjZkzzDp2SKs/zp6rCoECqiLMWzWZSNLfvpIAzF81ub4UkqU94/lQVGBRIFTEwazofOfWwEb/YJgV89NTDbfqWpJLnT1WBo2CkCnnJUU/joH1354Kla7ipzrzbx8yYxpmLZvuFJklDeP7URGdQIFXMwKzpDMyazup7NrNi7Ua2bN3OnlMmMzBrun1gJWkYnj81kRkUSBU158CpfolJUgs8f2oickyBJEmSVHEGBZIkSVLFGRRIkiRJFWdQIEmSJFWcQYEkSZJUcQYFkiRJUsUZFEiSJEkVZ1AgSZIkVZxBgSRJklRxBgWSJElSxRkUSJIkSRVnUCBJkiRVnEGBJEmSVHEGBZIkSVLFGRRIkiRJFWdQIEmSJFWcQYEkSZJUcQYFkiRJUsUZFEiSJEkV1zNBQUQcFxHfjYhNEfFIRNwWEW+JiF1Gkcc5EZEjPO4YkmbhCPt/dPxfrSRJktQ7Jne7AgAR8SLgW8BW4DJgE3AycB4wAJzRZFbLhtl2MjAfuLrB9uUN0t/QZNmS1D33roJ1y2HbZth1KsxcAAfM63atBB4bSX2h60FBROwFfAn4PbAwM28p178PuBY4PSJempmXjpRXZi6jzoV92drwmvLpPzZIviwzzxlt/SWpq9Ytg+UfhztXPH7bwQOw4F0wc2GnayXw2EjqK73Qfeh0YH/g0lpAAJCZW4H3lk9fP8YyXgAcBPwoM28bY16S1Btu/Tpc8uL6F51QrL/kxXDrJZ2tlzw2kvpO11sKgBPK5TV1tv0AeBg4LiJ2zcxtLZbxt+WyUSsBwKyIeBOwF/Br4PrMXNNieZLUXuuWwVVnQe4Yfr/cAVedCfs81V+lO8VjI6kP9UJQcGi5XD10Q2Zuj4j1wDOAmcCq0WYeEQcBzwceoBiv0Mhfl4/Bab8FvDYzf9tkWSsbbJrbTHpJatryj4980VmTO2D5P3jh2SkeG0l9qBe6D+1dLh9osL22fp8W838NsAvwjcx8uM723wBnA4cBUym6Mj0f+HfgNOCqiOiF90mSCveuatwtpZE7byjSqb08NpL61Li0FETEBuDgUST5Zma+bDzKHk55MV8bYPzFevtk5n8C/zlo1Rbgmoi4EfgJxexHJwPfGam8zDyiQT1WUsx8JEljt2556+mc9aa9PDaS+tR4dR+6g2I60WbdPejvWkvA3vV2HLT+/lHWCYpf/J9KMcD4Z6NJmJkPRsQ/Ae8BjqeJoECSOmLb5s6mU/M8NpL61LgEBZm5aAzJbweOBOYAj+mTHxGTgRnAdmBdC3nXBhjXbSVowm/K5R4tppek8bfr1M6mU/M8NpL6VC/0lb+2XJ5UZ9vxwO7AjaOdeSgi/gj4c0YeYDycY8tlKwGJJLXHzAWdTafmeWwk9aleCAqWABuBl0bEkbWVETEF+FD59AuDE0TE7hExNyKeNky+tQHGl2TmI412GlzmkPUvA14CPApc3swLkaSOOGBecfOr0Tj4OfZZ7wSPjaQ+1fWgIDMfBF5LcQG/LCK+HBEfpxjk+2yKoGHoL/1HU0xP+vV6eQ4ZYDzcvQkAlkTE2oi4NCI+ERGfjYibgEso7rL8d5m5YfSvTJLaaMG7oNmJ0WISLHhne+ujnTw2kvpQ14MCgMy8ElhAcbOy04A3A78D3ga8NDNzlFk+j2I2pGYGGH8BWE8xy9Abgb8BpgMXA0dm5sWjLFuS2m/mQjj5/JEvPmMSnHyB8+B3ksdGUh/qhZuXAZCZK4AXNLnvMiCG2X71cNuH7Psx4GPN7CtJPWX+y2GfpxU3v7rzhsdvP/g5xa/QXnR2nsdGUp/pmaBAktSCmQuLx72rirnut20uZrKZucB+6t3msZHURwwKJGkiOGCeF5q9ymMjqQ/0xJgCSZIkSd1jUCBJkiRVnEGBJEmSVHEGBZIkSVLFGRRIkiRJFWdQIEmSJFWcQYEkSZJUcQYFkiRJUsUZFEiSJEkVZ1AgSZIkVZxBgSRJklRxBgWSJElSxRkUSJIkSRVnUCBJkiRVnEGBJEmSVHEGBZIkSVLFGRRIkiRJFWdQIEmSJFWcQYEkSZJUcQYFkiRJUsUZFEiSJEkVZ1AgSZIkVZxBgSRJklRxBgWSJElSxU3udgUkSY+1+p7NrFi7kS1bt7PnlMkMzJrOnAOndrta6iA/A5I6zaBAknrEirUbOX/pGm5ev+lx246eMY2zFs1mYNb0LtRMneJnQFK32H1IknrAZT/+BYsvuqnuxSDAzes3sfiim7j8x3d1uGbqFD8DkrrJoECSumzF2o28+4qfsSOH329HwtlX3MaKtRs7UzF1jJ8BSd1mUCBJXXb+0jUjXgzW7Ei4YOma9lZIHednQFK3GRRIUhetvmdzw+4ijdy0fhOr79ncphqp0/wMSOoFBgWS1EWtdgOx+8jE4WdAUi8wKJCkLtqydXtH06n3+BmQ1AsMCiSpi/ac0trM0K2mU+/xMyCpFxgUSFIXtTrnvHPVTxx+BiT1AoMCSeqiOQdO5egZ00aV5pgZ07y77QTiZ0BSL+h6UBART4iIsyLiqxHxk4h4NCIyIv5mDHkeFxHfjYhNEfFIRNwWEW+JiF2GSfMXEbEsIh6IiC0RcVNEvKLVOkhSs85aNJtJ0dy+kwLOXDS7vRVSx/kZkNRtXQ8KgD2ATwOvBJ4E/HosmUXEi4AfAMcD3wY+CzwROA+4tEGaNwFXAf8N+AbwJeCPgIsj4hNjqY8kjWRg1nQ+cuphI14UTgr46KmH221kAvIzIKnbeiEoeBh4AfBHmfkk4CutZhQRe1Fc0P8eWJiZr8nMdwLPAn4InB4RLx2S5hDgE8Am4MjMfGNmvhU4HLgDeHtEPLvVOklSM15y1NO45DXHcEyDbiTHzJjGJa85hr886qkdrpk6xc+ApG7q+tQFmfkocPU4ZXc6sD/w9cy8ZVAZWyPivcBS4PU8tsXg1cCuwMcyc8OgNL+NiP8NXAS8jiKokKS2GZg1nYFZ01l9z2ZWrN3Ilq3b2XPKZAZmTbf/eEX4GZDULV0PCsbZCeXymjrbfkDRKnFcROyamduaSHP1kH0kqe3mHDjVC8CK8zMgqdMmWlBwaLlcPXRDZm6PiPXAM4CZwKom0vwqIh4CDoqI3TPz4eEKj4iVDTbNbabykiRJUjf0wpiC8bR3uXygwfba+n1aSLN3g+2SJElSXxuXloKI2AAcPIok38zMl41H2b0kM4+ot75sQZjf4epIkiRJTRmv7kN3AFtHsf/d41TuUCP9ql9bf/+QNNPLbfcNk6ZRS4IkSZLU18YlKMjMReORzzi4HTgSmAM8pn9/REwGZgDbgXVD0kwv0/xwSJonU9xH4ZcjjSeQJEmS+tVEG1Nwbbk8qc6244HdgRsHzTw0UprnD9lHkiRJmnD6MiiIiL0jYm75S/5gS4CNwEsj4shB+08BPlQ+/cKQNF8FtgFvKm9kVkuzL/D35dMLx7H6kiRJUk/piSlJI+Jsdk7b+axy+aqIeE759w2Z+eVBSV5McTH/NeCVtZWZ+WBEvJYiOFgWEZdS3Kn4hRRTjy4BLhtcdmauj4h3AhcAt0TEZcCjFDdCOwj4ZGZ64zJJkiRNWD0RFFB03VkwZN1x5aPmyzQhM6+MiAXAe4DTgCnAWuBtwAWZmXXSfKacQekdwMspWlD+C3hvZn5tdC9FkiRJ6i89ERRk5sJR7n8xcPEw21cALxhlnlcBV40mjSRJkjQRRJ0fzjXOIuK+3Xbbbdq8efO6XRVJkiRNYKtWreKRRx7ZlJn7jSadQUEHRMR6YC9gQxuyr43F+Hkb8tbYeXx6m8ent3l8epvHp7d5fHpXu4/NIcCDmTljNIkMCvpcebfkhndTVnd5fHqbx6e3eXx6m8ent3l8elevHpu+nJJUkiRJ0vgxKJAkSZIqzqBAkiRJqjiDAkmSJKniDAokSZKkinP2IUmSJKnibCmQJEmSKs6gQJIkSao4gwJJkiSp4gwKJEmSpIozKJAkSZIqzqBAkiRJqjiDAkmSJKniDAr6REQ8ISLOioivRsRPIuLRiMiI+JsW8jqkTNvocWk7XsNENp7HZ1Cex0XEdyNiU0Q8EhG3RcRbImKX8ax7lYzXezrC/8+P2lX/fhcRB0XEVyLi7ojYFhEbIuLTEbHvKPOZVqbbUOZzd5nvQe2qexWMx/GJiGUj/H9MaedrmKgi4vSI+ExEXB8RD5bv5TdazGtc/g+103gdn/JYNPrf+XU76j7Y5HYXoHGzB/Dp8u97gF8DTx1jnj8Frqyz/j/GmG8VjevxiYgXAd8CtgKXAZuAk4HzgAHgjDHUtZLa8J7eCVxcZ/0vW6/lxBURTwduBA4AvgP8HDgaOAs4KSIGMvO+JvLZr8xnDnAtcCkwF3gV8OcR8ezMXNeeVzFxjdfxGeTcBuu3j6mi1fVe4JnAFopzzNxWMmnDcVZhXI5P6QF2Xk8MtmUMeTYnM330wQN4IvB84Mnl83OABP6mhbwOKdNe3O3XNVEe43x89gLuBbYBRw5aP4XiZJ7AS7v9mvvpMd7vabn/sm6/rn56AN8r37c3D1n/qXL9hU3m88Vy/08OWX9muf6abr/WfnyM4/FZVlxadP81TaQH8FxgNhDAwvKYfKNbx9lH247PBmBDt16H3Yf6RGY+mplXZ+avul0XPd44H5/Tgf2BSzPzlkFlbKX4NQLg9eNQTpX4nnZR+evkiRRfeJ8bsvkDwEPA4ojYY4R89gQWl/ufM2TzZylab54XETPHXuvqGK/jo/bJzOsyc02WV46t8Di3z3gcn15g96Fq+6OI+DtgP+A+4IeZeVuX6yQ4oVxeU2fbD4CHgeMiYtfM3Na5avW1dryn+0TEq4EnUTT3rsxMxxPU99xy+f3M3DF4Q2ZujogVFBcrxwJLh8nnWGC3Mp/NQ/LZERHfA/62LM8uRM0br+PzBxHxEmAG8CiwCrjW81XXjftxVlvsGhEvA55GEajdBvwgM3/f7oINCqrtz8rHH0TEMuAVmfmLrtRIAIeWy9VDN2Tm9ohYDzwDmEnxZauRteM9fSZw0eAVEfFTYHFm/mwMdZ2IGr7/pTUUFyNzGP5ipJl8KPNR88br+Aw2dMKKeyPijZm5pIX6aXy04zhr/D0JuGTIuvUR8arMXN7Ogu0+VE0PA/8LOALYt3wsAK6j6Au31ObDrtq7XD7QYHtt/T7tr8qEMd7v6acoBifvD0wFjgKWUAQK10bEU1qr5oQ1Xu+//xvtMZ7v63coBvAfRNGqMxf4SJn2sog4qeVaaqz8/+l9XwUWUQQGewCHUYyjOgS4OiKe2c7CDQo6aISppuo9WppubCSZeW9mvj8zb83M+8vHDyh+IbgJmAW0PJVmv+qV46P6eun4ZObbM/PGzNyYmVsy85bMPINidqPpwDvaVbbUyzLzvMz8P5n5fzNza2benpl/D7yd4prjI12uotSzMvPczLw2M+/JzIcz8z8y83UUP0TtxuPHUo0ruw911h0U0yE26+52VaSeshvFl4FjgOOB8ztZfg/oleNT+7Vm7wbba+vvb1P5vWosx6dT7+mFwGkU/z/aabzef/832qMT7+uXKab/fVZETB06JkQd4f9P/7qQIrBu63eLQUEHZeaibtehCb8pl5XrPtRDx+d24EiKfp0rB2+IiMkUg/e2U7GBlGM8Pp16Tyv7/zOC28tlo77+s8tlo77O452PHqvt72tmbo2IzRTdVfcADAo6z/+f/tWR7xa7D2moY8tlpS44e8y15bJe39vjgd2BG53JY1Q69Z76/1PfdeXyxIh4zPdOREylGJ/xMDDS7E0/Ah4BBsp0g/OZRNEFcnB5as54HZ+GIuJQioBgM7Cx1Xw0Jm0/zmqbjny3GBRMYBGxd0TMjYgnD1k/f+gJoVy/CHhr+dT+8m3W6PhQDFjdCLw0Io4ctP8U4EPl0y90qJoTxajf04jYvTw+Txuy/vCIeMLQAiLicODD5VP/fwbJzDuA71MMlnvjkM3nUvz6dUlmPlRbWb73j7kraGZuoZiVYw8e37f2TWX+30vvaDwq43V8ImJGREwbmn9E7E8xgBKKe4V4V+M2iognlMfn6YPXt3KcNf4aHZ+ImFdvkpeIOITiPizQ5u+W6PP7LFRKRJzNzltnP4tippMb2TkN3w2Z+eVB+7+S4kT8tcx85aD1yyiaCW+kuB03wOHsnMv9fZlZu1BSk8br+JTbTqG4kN1KMbXfJuCFFFPKLQH+st9vktJpo31PI2IhxS9ryzNz4aD1F1PMrnI9cBfFXZLnUrRC7AJ8Cfg7j89jlV+ANwIHUMxQs4pi/NJzKborHJeZ9w3av7h1dGYMyWe/Mp85FC1ANwPzgBdR3LX6uPLiR6MwHsenPKddCNxA8YvmJoq51l9A0V/9FuDPMvP+tr+gCaY8f51SPn0S8DyK9/j6ct3GzHxHue8hwHrgzsw8ZEg+ozrOas54HJ+IOIdi3MAPKG7EuBl4OvDnwBTgu8CLM/PRtr2Q8b5Fso/2PShvHz/M4+Ih+7+ywfrXAP+H4q6GWyguan4BXAb8SbdfZ78+xuv4DNo+QHES+C1Fl4mfUbTk7NLt19qvj9G8p+y8Vf2yIetPAa4A1gIPUtyc6VfAVcALu/0ae/kBPJUiEP5V+b7dCXwa2LfOvll8RdXNZxrFRAh3Dnr/vwIc1O3X2M+PsR4fiukTLy7/r+4DfkcRGFwPvBl4YrdfY78+KFrGhvt+2TBo30OGrmv1OPvo3PGhmBr+n4GfUwz2/h3FWIJ/A15O+UN+Ox+2FEiSJEkV55gCSZIkqeIMCiRJkqSKMyiQJEmSKs6gQJIkSao4gwJJkiSp4gwKJEmSpIozKJAkSZIqzqBAkiRJqjiDAkmSJKniDAokSZKkijMokCRJkirOoECSJEmqOIMCSZIkqeIMCiRJkqSKMyiQJEmSKs6gQJIkSao4gwJJkiSp4v4flTw6VI3aqIsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 263,
       "width": 386
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx_0 = np.where(circles_labels==0)\n",
    "idx_1 = np.where(circles_labels==1)\n",
    "plt.scatter(circles_data[idx_0,0],circles_data[idx_0,1])\n",
    "plt.scatter(circles_data[idx_1,0],circles_data[idx_1,1])\n",
    "plt.axis('equal')\n",
    "plt.title('Original 2D data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracTrain = 0.8\n",
    "fracTest = 1 - fracTrain\n",
    "\n",
    "nTrain = int(nTot*fracTrain)\n",
    "nTest = nTot - nTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "repsTrain_solo = circles_data[:nTrain]\n",
    "repsTest_solo = circles_data[nTrain:]\n",
    "\n",
    "labelsTrain = circles_labels[:nTrain].astype(float)\n",
    "labelsTest = circles_labels[nTrain:].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimProj = 100\n",
    "A = np.random.rand(2,dimProj)\n",
    "\n",
    "repsTrain_proj = repsTrain_solo@A\n",
    "repsTest_proj = repsTest_solo@A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = Variable(torch.from_numpy(repsTrain_proj)).requires_grad_(True)\n",
    "yTrain = Variable(torch.from_numpy(labelsTrain)).requires_grad_(True)\n",
    "\n",
    "dataTest = Variable(torch.from_numpy(repsTest_proj)).requires_grad_(True)\n",
    "yTest = Variable(torch.from_numpy(labelsTest)).requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create dataset and dataloader\n",
    "tensorTrainData = TensorDataset(dataTrain,yTrain)\n",
    "tensorTestData = TensorDataset(dataTest,yTest)\n",
    "\n",
    "bs = 2 ## batch size\n",
    "train_loader = DataLoader(tensorTrainData, batch_size=bs, shuffle=True)\n",
    "train_loader_noShuffle = DataLoader(tensorTrainData, batch_size=bs, shuffle=False)\n",
    "test_loader = DataLoader(tensorTestData, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU, training on CPU\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('No GPU, training on CPU')\n",
    "else:\n",
    "    print('GPU found, training on GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPAE(\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLPAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPAE, self).__init__()\n",
    "        \n",
    "        ##Encoder\n",
    "        self.layer1 = torch.randn(50,100)\n",
    "        self.layer2 = torch.randn(50,50) ## latent layer ##R1\n",
    "        self.layer3 = torch.randn(50,50) ##R2\n",
    "        self.layer4 = torch.randn(100,50) ## recon layer\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        def firing_rate(x):\n",
    "            nSamp, nNodes = x.shape\n",
    "            firing_rate_mat = torch.zeros(nSamp,nNodes)\n",
    "            keep_idxs = torch.argsort(x,dim=1)[:,:20]\n",
    "            for kk in range(nSamp):\n",
    "                firing_rate_mat[kk,keep_idxs[kk]] = 1\n",
    "            return firing_rate_mat\n",
    "        \n",
    "        ## layer 1\n",
    "        frIn = firing_rate(x)\n",
    "        \n",
    "        x = F.relu(self.layer1 @ (x.T)).T\n",
    "        frL1 = firing_rate(x)\n",
    "        \n",
    "        x = F.relu(self.layer2 @ (x.T)).T\n",
    "        print(x.shape)\n",
    "        frL2 = firing_rate(x)\n",
    "        \n",
    "        x_latent = self.dropout(x)\n",
    "        x = F.relu(self.layer3@ (x.T)).T\n",
    "        print(x.shape)\n",
    "        frL3 = firing_rate(x)\n",
    "       \n",
    "        x_recon = (self.layer4 @ (x.T)).T\n",
    "        print(x_recon.shape)\n",
    "        frOut = firing_rate(x_recon)\n",
    "        \n",
    "        return x_recon, frIn, frL1, frL2, frL3, frOut, x_latent\n",
    "\n",
    "#create the NN\n",
    "model = MLPAE()\n",
    "print(model)\n",
    "\n",
    "#move tensors to GPU if available\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial pass for MLPAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 50])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 100])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 100])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 100])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 100])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 100])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 100])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 100])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 100])\n"
     ]
    }
   ],
   "source": [
    "for data, target in train_loader:\n",
    "    data, target = data.float(), target.float()\n",
    "    reconTP, frInTP, frL1TP, frL2TP, frL3TP, frOutTP, latentTP = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsize, dimIn = frInTP.shape\n",
    "_, dim1 = frL1TP.shape\n",
    "_, dim2 = frL2TP.shape\n",
    "_, dim3 = frL3TP.shape\n",
    "_, dimOut = frOutTP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frOutTP.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define updater network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updater(\n",
      "  (layer1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (layer2): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Updater(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Updater, self).__init__()\n",
    "        \n",
    "        ##Encoder\n",
    "        self.layer1 = nn.Linear(2,2)\n",
    "        self.layer2 = nn.Linear(2,1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        ## layer 1\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.tanh(self.layer2(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "#create the NN\n",
    "updater = Updater()\n",
    "print(updater)\n",
    "\n",
    "#move tensors to GPU if available\n",
    "if train_on_gpu:\n",
    "    updater.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(updater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.0171, -0.3496],\n",
      "        [ 0.5951, -0.5115]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.2295, -0.3237], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.4938, -0.5016]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1260], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(updater.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.0171, -0.3496],\n",
      "        [ 0.5951, -0.5115]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.2295, -0.3237], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.4938, -0.5016]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1260], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(updater.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial pass for updater "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i1 = 0\n",
    "# j1 = 0\n",
    "\n",
    "# xx = torch.cat((frInT[:,i1].view(-1,1),frL1T[:,j1].view(-1,1)),1)\n",
    "# if train_on_gpu:\n",
    "#     xx = xx.cuda()\n",
    "# print(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oo = updater(xx)\n",
    "# torch.mean(oo,0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deltaW(di,dj,fri,frj,upM,GPU):\n",
    "    dw = torch.zeros(dj,di)\n",
    "    for ii in range(di):\n",
    "        for jj in range(dj):\n",
    "            frBatch = torch.cat((fri[:,ii].view(-1,1),frj[:,jj].view(-1,1)),1)\n",
    "            if GPU:\n",
    "                frBatch, dw = frBatch.cuda(), dw.cuda()\n",
    "            dw[jj,ii] = torch.mean(upM(frBatch),0)[0]\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dwsL1 = deltaW(dimIn,dim1,frInTP,frL1TP,updater,train_on_gpu)\n",
    "# dwsL4 = deltaW(dim3,dimOut,frL3TP,frOutTP,updater,train_on_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dwsL4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oldClone = model.layer1.weight.clone()\n",
    "# oldClone += (dwsL12)\n",
    "# model.layer1.weight = nn.Parameter(oldClone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateSynapses(bigModel,updaterModel,dims,firingRates,GPU):\n",
    "        \n",
    "#     recon, frIn, frL1, frL2, frL3, frOut, latents = bigModel(batchData)\n",
    "    \n",
    "#     bsize, dimIn = frIn.shape\n",
    "#     _, dim1 = frL1.shape\n",
    "#     _, dim2 = frL2.shape\n",
    "#     _, dim3 = frL3.shape\n",
    "#     _, dimOut = frOut.shape\n",
    "\n",
    "    frIn, frL1, frL2, frL3, frOut = firingRates\n",
    "\n",
    "    dimIn, dim1, dim2, dim3, dimOut = dims\n",
    "        \n",
    "    ## layer1\n",
    "\n",
    "    bigModel.layer1 = bigModel.layer1 + deltaW(dimIn,dim1,frIn,frL1,upM=updaterModel,GPU=GPU)\n",
    "        \n",
    "    ## layer2\n",
    "    bigModel.layer2 = bigModel.layer2 + deltaW(dim1,dim2,frL1,frL2,upM=updaterModel,GPU=GPU)\n",
    "    \n",
    "    ## layer3\n",
    "    bigModel.layer3 = bigModel.layer3 + deltaW(dim2,dim3,frL2,frL3,upM=updaterModel,GPU=GPU)\n",
    "    \n",
    "    ## layer4\n",
    "    bigModel.layer4 = bigModel.layer4 + deltaW(dim3,dimOut,frL3,frOut,upM=updaterModel,GPU=GPU)\n",
    "    \n",
    "    bigModel = bigModel.eval()\n",
    "    \n",
    "    return bigModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#optimizer\n",
    "eta = 0.001\n",
    "optimizer = torch.optim.Adam(updater.parameters(), lr=eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addresses to collect activations and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = '/home/kshu/gatech/8803/CS8803FinalProject/'\n",
    "npp = 'saved-models-hebbian-MLPAE/'\n",
    "pp_npy = pp+npp+'npys/'\n",
    "pp_pts = pp+npp+'pts/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train updater model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimsList = [dimProj,n_latent,n_latent,n_latent,dimProj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict()\n"
     ]
    }
   ],
   "source": [
    "print(updater._parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.0171, -0.3496],\n",
      "        [ 0.5951, -0.5115]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.2295, -0.3237], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.4938, -0.5016]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1260], requires_grad=True)]\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 100])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 50])\n",
      "torch.Size([2, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-682f5450e97c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#calculate the loss for the batch on meta-objective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#update parameters in direction of the -ve gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time."
     ]
    }
   ],
   "source": [
    "#number of epochs\n",
    "n_epochs = 4\n",
    "div = n_epochs//4 ## try ensuring that number used to divide by is a factor of n_epochs\n",
    "train_losses = np.zeros(n_epochs)\n",
    "\n",
    "train_loss_min = np.Inf\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in tqdm(range(1,n_epochs+1)):\n",
    "    train_loss = 0.0\n",
    "    cnt = 0\n",
    "    \n",
    "    #train updater model\n",
    "    updater.train()\n",
    "    model.eval()\n",
    "    for data, target in train_loader:\n",
    "        if train_on_gpu:\n",
    "            data, target = data.float().cuda(), target.float().cuda()\n",
    "        else:\n",
    "            data, target = data.float(), target.float()\n",
    "        print(list(updater.parameters()))\n",
    "        optimizer.zero_grad() #clears older gradients\n",
    "        \n",
    "        recon_train, frIn_train, frL1_train, frL2_train, frL3_train, frOut_train, latents_train = model(data) #forward pass\n",
    "        firingRates_tup = (frIn_train, frL1_train, frL2_train, frL3_train, frOut_train)\n",
    "\n",
    "        model = updateSynapses(model,updater,dimsList,firingRates_tup,train_on_gpu) ##update synapses of the main model\n",
    "        \n",
    "        loss = criterion(model(data)[0],data) #calculate the loss for the batch on meta-objective\n",
    "        loss.backward() #backprop\n",
    "        print(\"gradient: \", list(updater.layer1.parameters())[0].grad)\n",
    "        optimizer.step() #update parameters in direction of the -ve gradient\n",
    "        print(list(updater.parameters()))\n",
    "        train_loss += loss.item()*data.size(0) #update training loss\n",
    "        \n",
    "        \n",
    "        \n",
    "    #calculate average loss\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    \n",
    "    #training/validation stats\n",
    "#     print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "    train_losses[epoch-1] = train_loss\n",
    "    \n",
    "    #save model if the training loss decreased\n",
    "    if train_loss <= train_loss_min:\n",
    "        print('Epoch: {}, Train Loss Decreased!! ({:.6f}-->{:.6f})'.format(epoch,train_loss_min,train_loss))\n",
    "        torch.save(model.state_dict(),pp_pts+'hebbian-MLPAE.pt')\n",
    "        torch.save(updater.state_dict(),pp_pts+'NN-updater.pt')\n",
    "        train_loss_min = train_loss\n",
    "        best_epoch = epoch\n",
    "        \n",
    "    if epoch%div == 0:\n",
    "        torch.save(model.state_dict(), pp_pts+'hebbian-MLPAE_epoch_'+str(epoch)+'.pt')\n",
    "        torch.save(updater.state_dict(), pp_pts+'NN-updater_epoch_'+str(epoch)+'.pt')\n",
    "        \n",
    "        activations_hidden_np = np.zeros((nTest,n_latent))\n",
    "        \n",
    "        activations_out_np = np.zeros((nTest,dimProj))\n",
    "        \n",
    "        # track test loss\n",
    "        test_loss = 0.0\n",
    "        \n",
    "        model.eval()\n",
    "        updater.eval()\n",
    "        for data_test, target_test in test_loader:\n",
    "            data_test, target_test = data_test.float(), target_test.float()\n",
    "            if train_on_gpu:\n",
    "                data_test, target_test = data_test.cuda(), target_test.cuda()\n",
    "            \n",
    "            \n",
    "            ## outputs\n",
    "            output_test, frIn_test, frL1_test, frL2_test, frL3_test, frOut_test, latents_test = model(data_test)\n",
    "            \n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output_test,data_test)\n",
    "            \n",
    "            # update test loss \n",
    "            test_loss += loss.item()*data_test.size(0)\n",
    "            \n",
    "            latents_test = np.squeeze(latents_test.detach().cpu().numpy())\n",
    "            output_test = np.squeeze(output_test.detach().cpu().numpy())\n",
    "            \n",
    "            for i in range(bs):\n",
    "                if i < len(data_test):\n",
    "                    label = target_test.data[i]\n",
    "\n",
    "                    activations_hidden_np[cnt] = latents_test[i]\n",
    "\n",
    "                    activations_out_np[cnt] = output_test[i,-1]\n",
    "\n",
    "                    cnt += 1\n",
    "\n",
    "        np.save(pp_npy+'hebbian-MLPAE_latent_epoch_'+str(epoch), activations_hidden_np)\n",
    "        \n",
    "        np.save(pp_npy+'hebbian-MLPAE_out_epoch_'+str(epoch), activations_out_np)\n",
    "        \n",
    "        # average test loss\n",
    "        test_loss = test_loss/len(test_loader.dataset)\n",
    "        print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((train_losses),'-x')\n",
    "plt.xticks(np.arange(n_epochs),np.arange(n_epochs)+1)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
