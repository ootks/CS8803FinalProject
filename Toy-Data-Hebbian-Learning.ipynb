{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons, make_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTot = 1000\n",
    "circles_data, circles_labels = make_circles(n_samples = nTot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_0 = np.where(circles_labels==0)\n",
    "# idx_1 = np.where(circles_labels==1)\n",
    "# plt.scatter(circles_data[idx_0,0],circles_data[idx_0,1])\n",
    "# plt.scatter(circles_data[idx_1,0],circles_data[idx_1,1])\n",
    "# plt.axis('equal')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split datat into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracTrain = 0.8\n",
    "fracTest = 1 - fracTrain\n",
    "\n",
    "nTrain = int(nTot*fracTrain)\n",
    "nTest = nTot - nTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nRounds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "repsTrain_solo = circles_data[:nTrain]\n",
    "repsTest_solo = circles_data[nTrain:]\n",
    "\n",
    "labelsTrain = circles_labels[:nTrain].astype(float)\n",
    "labelsTest = circles_labels[nTrain:].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimProj = 10\n",
    "A = np.random.rand(2,dimProj)\n",
    "\n",
    "repsTrain_proj = repsTrain_solo@A\n",
    "repsTest_proj = repsTest_solo@A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSequences(dataset,Trounds=1):\n",
    "    if Trounds==1:\n",
    "        return np.expand_dims(dataset,1)\n",
    "    elif Trounds>1:\n",
    "        numSamps, numFeats = dataset.shape\n",
    "        dataset_sequential = np.zeros((numSamps,Trounds,numFeats))\n",
    "        for kk in range(Trounds):\n",
    "            dataset_sequential[:,kk,:] = dataset\n",
    "        return dataset_sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "repsTrain = makeSequences(repsTrain_proj,nRounds)\n",
    "repsTest = makeSequences(repsTest_proj,nRounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = Variable(torch.from_numpy(repsTrain)).requires_grad_(True)\n",
    "yTrain = Variable(torch.from_numpy(labelsTrain)).requires_grad_(True)\n",
    "\n",
    "dataTest = Variable(torch.from_numpy(repsTest)).requires_grad_(True)\n",
    "yTest = Variable(torch.from_numpy(labelsTest)).requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create dataset and dataloader\n",
    "tensorTrainData = TensorDataset(dataTrain,yTrain)\n",
    "tensorTestData = TensorDataset(dataTest,yTest)\n",
    "\n",
    "bs = 128 ## batch size\n",
    "train_loader = DataLoader(tensorTrainData, batch_size=bs, shuffle=True)\n",
    "test_loader = DataLoader(tensorTestData, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found, training on GPU\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('No GPU, training on CPU')\n",
    "else:\n",
    "    print('GPU found, training on GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNpredictor(\n",
      "  (layer1): RNN(10, 5, batch_first=True)\n",
      "  (fc): Linear(in_features=5, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNNpredictor(nn.Module):\n",
    "    def __init__(self, seq_len=3, n_features=10, hidden_dim=5):\n",
    "        super(RNNpredictor, self).__init__()\n",
    "        \n",
    "        ##Encoder\n",
    "        self.layer1 = nn.RNN(input_size = n_features, hidden_size = hidden_dim,\n",
    "                                 num_layers = 1, batch_first = True, bidirectional = False)\n",
    "        \n",
    "        ## FC layer\n",
    "        self.fc = nn.Linear(hidden_dim, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        ## layer 1\n",
    "        x, lastHidden = self.layer1(x)\n",
    "        \n",
    "        classifyOp = self.fc(lastHidden)\n",
    "        \n",
    "        return classifyOp\n",
    "\n",
    "#create the NN\n",
    "model = RNNpredictor()\n",
    "print(model)\n",
    "\n",
    "#move tensors to GPU if available\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 10])\n",
      "torch.Size([1, 32, 2])\n"
     ]
    }
   ],
   "source": [
    "for data, target in train_loader:\n",
    "    if train_on_gpu:\n",
    "        data, target = data.float().cuda(), target.float().cuda()\n",
    "        op = model(data)\n",
    "\n",
    "print(data.shape)\n",
    "print(op.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hebbian update - MLP mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPAE, self).__init__()\n",
    "        \n",
    "        ##Encoder\n",
    "        self.layer1 = nn.Linear(10, 5)\n",
    "        self.layer2 = nn.Linear(5,2)\n",
    "        self.layer3 = nn.Linear(2, 5)\n",
    "        self.layer4 = nn.Linear(5,10)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        ## layer 1\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x_latent = self.dropout(x)\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = self.dropout(x)\n",
    "        x_recon = self.layer4(x)\n",
    "        \n",
    "        return x_recon, x_latent\n",
    "\n",
    "#create the NN\n",
    "model = MLPAE()\n",
    "print(model)\n",
    "\n",
    "#move tensors to GPU if available\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
